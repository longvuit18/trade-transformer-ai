{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>ema2</th>\n",
       "      <th>ema9</th>\n",
       "      <th>ema25</th>\n",
       "      <th>ema97</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577836800000</td>\n",
       "      <td>7176.26</td>\n",
       "      <td>7180.588135</td>\n",
       "      <td>7185.190592</td>\n",
       "      <td>7185.647417</td>\n",
       "      <td>7218.553299</td>\n",
       "      <td>1037.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1577837700000</td>\n",
       "      <td>7172.36</td>\n",
       "      <td>7175.102712</td>\n",
       "      <td>7182.624474</td>\n",
       "      <td>7184.625308</td>\n",
       "      <td>7217.610579</td>\n",
       "      <td>707.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1577838600000</td>\n",
       "      <td>7174.83</td>\n",
       "      <td>7174.920904</td>\n",
       "      <td>7181.065579</td>\n",
       "      <td>7183.871823</td>\n",
       "      <td>7216.737506</td>\n",
       "      <td>325.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577839500000</td>\n",
       "      <td>7171.55</td>\n",
       "      <td>7172.673635</td>\n",
       "      <td>7179.162463</td>\n",
       "      <td>7182.923990</td>\n",
       "      <td>7215.815312</td>\n",
       "      <td>378.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1577840400000</td>\n",
       "      <td>7186.60</td>\n",
       "      <td>7181.957878</td>\n",
       "      <td>7180.649971</td>\n",
       "      <td>7183.206760</td>\n",
       "      <td>7215.219081</td>\n",
       "      <td>555.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115194</th>\n",
       "      <td>1681511400000</td>\n",
       "      <td>30410.80</td>\n",
       "      <td>30411.070887</td>\n",
       "      <td>30409.768169</td>\n",
       "      <td>30390.689758</td>\n",
       "      <td>30456.936083</td>\n",
       "      <td>1418.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115195</th>\n",
       "      <td>1681512300000</td>\n",
       "      <td>30416.20</td>\n",
       "      <td>30414.490296</td>\n",
       "      <td>30411.054535</td>\n",
       "      <td>30392.652084</td>\n",
       "      <td>30456.104735</td>\n",
       "      <td>1238.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115196</th>\n",
       "      <td>1681513200000</td>\n",
       "      <td>30413.20</td>\n",
       "      <td>30413.630099</td>\n",
       "      <td>30411.483628</td>\n",
       "      <td>30394.232693</td>\n",
       "      <td>30455.229128</td>\n",
       "      <td>1672.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115197</th>\n",
       "      <td>1681514100000</td>\n",
       "      <td>30402.50</td>\n",
       "      <td>30406.210033</td>\n",
       "      <td>30409.686902</td>\n",
       "      <td>30394.868640</td>\n",
       "      <td>30454.153023</td>\n",
       "      <td>3117.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115198</th>\n",
       "      <td>1681515000000</td>\n",
       "      <td>30373.50</td>\n",
       "      <td>30384.403344</td>\n",
       "      <td>30402.449522</td>\n",
       "      <td>30393.224898</td>\n",
       "      <td>30452.507043</td>\n",
       "      <td>1079.406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115199 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     close          ema2          ema9         ema25  \\\n",
       "0       1577836800000   7176.26   7180.588135   7185.190592   7185.647417   \n",
       "1       1577837700000   7172.36   7175.102712   7182.624474   7184.625308   \n",
       "2       1577838600000   7174.83   7174.920904   7181.065579   7183.871823   \n",
       "3       1577839500000   7171.55   7172.673635   7179.162463   7182.923990   \n",
       "4       1577840400000   7186.60   7181.957878   7180.649971   7183.206760   \n",
       "...               ...       ...           ...           ...           ...   \n",
       "115194  1681511400000  30410.80  30411.070887  30409.768169  30390.689758   \n",
       "115195  1681512300000  30416.20  30414.490296  30411.054535  30392.652084   \n",
       "115196  1681513200000  30413.20  30413.630099  30411.483628  30394.232693   \n",
       "115197  1681514100000  30402.50  30406.210033  30409.686902  30394.868640   \n",
       "115198  1681515000000  30373.50  30384.403344  30402.449522  30393.224898   \n",
       "\n",
       "               ema97    volume  \n",
       "0        7218.553299  1037.337  \n",
       "1        7217.610579   707.833  \n",
       "2        7216.737506   325.246  \n",
       "3        7215.815312   378.633  \n",
       "4        7215.219081   555.389  \n",
       "...              ...       ...  \n",
       "115194  30456.936083  1418.447  \n",
       "115195  30456.104735  1238.588  \n",
       "115196  30455.229128  1672.811  \n",
       "115197  30454.153023  3117.508  \n",
       "115198  30452.507043  1079.406  \n",
       "\n",
       "[115199 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data Bitcoin từ tệp csv\n",
    "data = pd.read_csv('normalized-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ra kích thước của tập dữ liệu\n",
      "(91391, 672, 6)\n",
      "(91391, 96)\n",
      "(22272, 672, 6)\n",
      "(22272, 96)\n"
     ]
    }
   ],
   "source": [
    "# chuẩn hóa dữ liệu trong khoảng [0,1] sử dụng minmaxscaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(\n",
    "    data[['close', 'ema2', 'ema9', 'ema25', 'ema97', 'volume']].values)\n",
    "# len(scaled_data)# có 115199 bản ghi\n",
    "train_data = scaled_data[:int(len(scaled_data)*0.8)]\n",
    "test_data = scaled_data[int(len(scaled_data)*0.8):]\n",
    "def create_sequences(data, seq_length=672, output_length= 96):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-output_length):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[(i+seq_length):(i+seq_length+output_length)]\n",
    "        ema2_predict = []\n",
    "        for i in y:\n",
    "            ema2_predict.append(i[1])\n",
    "        xs.append(x)\n",
    "        ys.append(ema2_predict)\n",
    "    return np.array(xs), np.array(ys)\n",
    "train_x, train_y = create_sequences(train_data)\n",
    "test_x, test_y = create_sequences(test_data)\n",
    "# kiểm tra kích thước của tập dữ liệu\n",
    "print('in ra kích thước của tập dữ liệu')\n",
    "print(train_x.shape) #(91391, 672, 6)\n",
    "print(train_y.shape) #(91391, 96, 6)\n",
    "print(test_x.shape) #(22272, 672, 6)\n",
    "print(test_y.shape) #(22272, 96, 6)\n",
    "# chuyển đổi dữ liệu thành các tensor\n",
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).float()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "test_y = torch.from_numpy(test_y).float()\n",
    "# tạo dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "test_data = TensorDataset(test_x, test_y)\n",
    "\n",
    "# tạo dataloader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "# kiểm tra kích thước của tập dữ liệu\n",
    "# print(len(train_loader)) #1428\n",
    "# print(len(test_loader)) #348\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
    "            num_encoder_layers,\n",
    "        )\n",
    "        self.memory = torch.rand(2, 672, 64)\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead),\n",
    "            num_decoder_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(d_model, 96) # linear not sequence\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x,self.memory)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Transformer(d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6)\n",
    "\n",
    "# Khởi tạo đầu vào\n",
    "x = torch.randn((3, 672, 64))\n",
    "\n",
    "# Tiến hành forward propagation\n",
    "output = model(x)\n",
    "\n",
    "# In đầu ra\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu Bitcoin từ tệp CSV\n",
    "data = pd.read_csv('normalized-data.csv')\n",
    "\n",
    "# Chuẩn hóa dữ liệu vào khoảng [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(\n",
    "    data[['close', 'ema2', 'ema9', 'ema25', 'ema97', 'volume']].values)\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_data = scaled_data[:800]\n",
    "test_data = scaled_data[800:]\n",
    "\n",
    "# Hàm tạo batch từ dữ liệu chuỗi thời gian\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length, output_length = 92):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length - output_length):\n",
    "        sequence = data[i:i + seq_length]\n",
    "        closeList = []\n",
    "        ema2List = []\n",
    "        ema9List = []\n",
    "        ema25List = []\n",
    "        ema97List = []\n",
    "        volumeList = []\n",
    "        ema2ListOutput = []\n",
    "        for k in range(len(sequence)):\n",
    "            closeList.append(sequence[k][0])\n",
    "            ema2List.append(sequence[k][1])\n",
    "            ema9List.append(sequence[k][2])\n",
    "            ema25List.append(sequence[k][3])\n",
    "            ema97List.append(sequence[k][4])\n",
    "            volumeList.append(sequence[k][5])\n",
    "        input_matrix = np.stack([closeList, ema9List, ema25List, ema97List, volumeList], axis=1)\n",
    "        for k in range(i + seq_length, i + seq_length + output_length):\n",
    "            ema2ListOutput.append(data[k][1])\n",
    "        sequences.append((input_matrix, ema2ListOutput))\n",
    "    return sequences\n",
    "\n",
    "# Định nghĩa kiến trúc mô hình Transformer\n",
    "# Định nghĩa kiến trúc mô hình Transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder( # -1, 672, 6\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
    "            num_encoder_layers,\n",
    "        )\n",
    "        self.memory = torch.rand(1, 672, 6)\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead),\n",
    "            num_decoder_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(d_model, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x,self.memory)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Transformer(d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6)\n",
    "# Cài đặt các siêu tham số\n",
    "batch_size = 64\n",
    "seq_length = 128\n",
    "output_length = 92\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Khởi tạo mô hình và bộ tối ưu\n",
    "model = Transformer().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "# Chuyển đổi dữ liệu huấn luyện và tạo batch\n",
    "train_sequences = create_sequences(train_data, seq_length=644)\n",
    "# print(train_sequences[0])\n",
    "train_inputs = torch.tensor(\n",
    "    np.array([seq for seq, _ in train_sequences]), dtype=torch.float32)\n",
    "train_targets = torch.tensor(\n",
    "    np.array([target for _, target in train_sequences]), dtype=torch.float32)\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_inputs.transpose(1, 2), train_targets)  # Chuyển vị train_inputs\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "#Huấn luyện mô hình\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs.unsqueeze(2))\n",
    "        loss = criterion(outputs.squeeze(), batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "model.eval()\n",
    "test_sequences = create_sequences(test_data, seq_length=10)\n",
    "test_inputs = torch.tensor([seq for seq, _ in test_sequences], dtype=torch.float32)\n",
    "test_targets = torch.tensor([target for _, target in test_sequences], dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_inputs.unsqueeze(2))\n",
    "test_loss = criterion(test_outputs.squeeze(), test_targets)\n",
    "print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
